### 2024/3/7

1.  实验了利用lstm进行number_recall任务相较于STM的优缺点。STM相较于lstm收敛速度更快。`lstm_number_recall.py`文件中的代码是相关实现。在该参数下，lstm在50 epoch下完成收敛，而STM能在30 epoch下完成收敛。可能是任务较为简单，无法体现两者之间的差距。在实验过程中，可以观察到lstm在前25 epoch中loss基本无改变，准确率也是低于0.2，在25 epoch后loss开始迅速减小，并在接下来25 epoch中迅速收敛至0。除此之外，还尝试在输入最后一组数据并求得输出之前，拼接一个提示向量，用于表示接下来需要输出一个预测值，但在实际过程中，添加了这个向量反而使得模型收敛速度变慢，并无预料中的加速收敛和增大准确率的作用（这里任务过于简单，都能做到100%正确，因此可能无法体现这个提示向量的作用）。

总结：STM并未表现出明显优于lstm的地方，建议之后加大任务难度重新测试。rnn的训练需要更多的epoch，前期loss下降不明显是正常现象。

补充：后续添加了重复部分和提示向量的消融实验。添加随机重复部分后依旧能在原模型基础上在5 epoch内收敛。消融实验显示提示向量没有作用，直接删除也不会对原模型表现有所影响。

2.  猜想部分：
    1.  关于HumanAI，目前认为Memory的整理与优化是关键，不过目前还没有找到合适的方法。任务选择上也没有合适的任务。
    2.  简单情况下，HumanAI的任务应该在处理data并存入Memory后能重复提取Memory内容直到输出可以结束，这里其实可以选择是重复处理Memory内容还是重复读取data来实现，重复读取Memory对隐空间的要求更高，重复读取data则对训练方式要求更高。
    3.  一个重点是Memory的内容与优化方式。
    4.  关于任务，可以尝试以顺序重复遍历文本块，然后让模型选择当前文本块是否要输入进来。
    5.  不考虑长期记忆的情况下，可以尝试在遍历了一遍文本块后，对随着文本块一起输入的[t,d]的记忆矩阵进行部分遗忘，然后重新遍历文本块，理论上因为有部分先前的记忆，重新生成填入的记忆会更加优秀。在执行若干次重复遍历后，尝试让模型生成结果。
    6.  通过遗忘部分内容并重建该部分内容可能获得意想不到的效果，但该方法应该只能作用于单个文本样例上，因为遗忘后的重建有相应的原文本可以直接读取，但是其他无关的短期记忆没有相应源头用于重建。
    7.  选择性地重复读取data应该是一个潜在收益非常大的方法，但是训练可以预见相当困难。这里给些建议：添加一个提示向量和当前帧一同输入transformer得到下一帧是要读入还是思考(思考指没有新内容输入，仅闪存进行处理)
    8.  简单情况下，可以把长期记忆看做优秀的短期记忆。生成短期记忆的方式应该可以从"重复"入手。
    9.  从闪存提取短期记忆时，可以尝试在开始训练的时候使用[该文章](https://spaces.ac.cn/archives/8620/comment-page-1)最后的公式$x_{t+1}=x_t+\alpha_tF_t(x_t)$，保证记忆不会因为初始映射矩阵而错乱难以训练。(实际上是一种升级版残差，训练一开始也能保证输入==输出)

### 2024/3/9

1.  transformer架构下，在1024特征维度下，[t,b,d]拆分成n*[t0,b,d] (其中t=n*t0)后，速度大大提升。因此可以实践2024/3/7-2_5的方案。